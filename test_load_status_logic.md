# 负载状态判断逻辑测试说明

## 🎯 修复内容

原问题：当网络最大值（`net_up_max` 或 `net_down_max`）为0时，网络指标不会触发高负载判断，导致即使其他指标（CPU、内存）超过阈值，仍可能显示为正常状态。

修复后逻辑：**任一指标超过阈值即判定为高负载，网络指标只有在设置了最大值且大于0时才参与判断。**

## 📊 测试用例

### 用例1: CPU超阈值 + 网络最大值为0
```
CPU: 95% (阈值90%) ❌ 超过
内存: 50% (阈值90%) ✅ 正常
网络上行: 任意值 (最大值=0) ⚪ 不检查
网络下行: 任意值 (最大值=0) ⚪ 不检查
结果: HIGH ✅
```

### 用例2: 内存超阈值 + 网络最大值为0
```
CPU: 50% (阈值90%) ✅ 正常
内存: 95% (阈值90%) ❌ 超过
网络上行: 任意值 (最大值=0) ⚪ 不检查
网络下行: 任意值 (最大值=0) ⚪ 不检查
结果: HIGH ✅
```

### 用例3: 所有基础指标正常 + 网络最大值为0
```
CPU: 50% (阈值90%) ✅ 正常
内存: 50% (阈值90%) ✅ 正常
网络上行: 800Mbps (最大值=0) ⚪ 不检查（即使很高也不检查）
网络下行: 800Mbps (最大值=0) ⚪ 不检查（即使很高也不检查）
结果: NORMAL ✅
```

### 用例4: 网络上行超阈值 + 有最大值设置
```
CPU: 50% (阈值90%) ✅ 正常
内存: 50% (阈值90%) ✅ 正常
网络上行: 80Mbps (最大值100Mbps, 阈值80%) ❌ 超过80Mbps
网络下行: 40Mbps (最大值100Mbps, 阈值80%) ✅ 低于80Mbps
结果: HIGH ✅
```

### 用例5: 所有指标正常（包括网络）
```
CPU: 50% (阈值90%) ✅ 正常
内存: 50% (阈值90%) ✅ 正常
网络上行: 40Mbps (最大值100Mbps, 阈值80%) ✅ 低于80Mbps
网络下行: 40Mbps (最大值100Mbps, 阈值80%) ✅ 低于80Mbps
结果: NORMAL ✅
```

## 🔧 关键修复点

1. **独立指标判断**: 每个指标独立判断，任一超过阈值即返回"high"
2. **网络指标条件检查**: 只有当 `NetUpMax > 0` 或 `NetDownMax > 0` 时才检查对应的网络指标
3. **详细日志记录**: 添加了详细的日志记录，便于调试和监控
4. **前端用户提示**: 在配置界面明确提示当网络最大值为0时不会检查该项

## 🚀 实际应用场景

### 场景A: 新部署的服务器
- 网络最大值初始为0（尚未记录到网络峰值）
- 但CPU或内存可能因为初始化进程而短暂飙高
- **结果**: 能正确识别为高负载状态 ✅

### 场景B: 纯计算服务器
- 网络流量很小，管理员不关心网络负载
- 只关心CPU和内存负载
- **结果**: 可以只配置CPU/内存阈值，网络保持0不参与判断 ✅

### 场景C: 高网络负载服务器
- 经过一段时间运行，系统自动记录了网络峰值
- 所有指标都参与负载判断
- **结果**: 全面监控，任一指标异常都能及时发现 ✅

## ✅ 测试验证

运行后端测试：
```bash
cd backend && go test ./internal/service -v
```

所有测试用例通过，验证逻辑修复正确。